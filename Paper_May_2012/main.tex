\documentclass[prodmode,acmtoms]{acmsmall}
%  

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
\acmVolume{0}
\acmNumber{0}
\acmArticle{00}
\acmYear{0000}
\acmMonth{0}

%
%%% User-requested packages placed after this line %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsfonts,amssymb,amsmath}
\usepackage{booktabs,dcolumn}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{enumerate,graphicx}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{listings}

% \usepackage[center]{subfigure}
\numberwithin{equation}{section}
\usepackage{braket}                             %Provides \Set for typing sets
\usepackage{float}
\usepackage{subfig}


%%% User's macros placed after this line %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\IfFileExists{dsfont.sty}%
%\usepackage{dsfont}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\deal}{\texttt{deal.II}}
\newcommand{\dope}{\texttt{DOpElib}}
\newcommand{\re}{\operatorname{Re}}

\newcommand{\todo}[1]{\textbf{\textsc{\textcolor{black}{TODO: #1}}}}
%\newcommand{\mymarginpar}[1]{\marginpar{\textcolor{red}{\scriptsize{#1}}}}
\newcommand{\mymarginpar}[1]{\marginpar{\textcolor{red}{\normalsize{#1}}}}
%
\begin{document}
\markboth{C. Goll, T. Wick, and W. Wollner}{DOpElib: A Goal Oriented Software Library}

\title{DOpElib: A Goal Oriented Software Library for Computing PDEs and Optimization Problems}

\author{CHRISTIAN GOLL
\affil{University of Heidelberg}
THOMAS WICK
\affil{The University of Texas at Austin}
WINNIFRIED WOLLNER
\affil{University of Hamburg}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
In this article, we describe the software library 
\textit{Differential Equations and Optimization Environment} (\dope{}).
The main feature of \dope{} is that it provides a unified interface to high level algorithms 
such as time stepping methods, nonlinear solvers and optimization routines. This structure ensures 
that first of all the user is required to write those sections of code that are specific to 
the considered problem. Second, the exchange of parts of the used routines is possible 
with the need for just a few lines of code to change.
The article illustrates performance and features 
of the software package by four numerical tests. 
\end{abstract}

%\category{C.2.2}{Computer-Communication Networks}{Network Protocols}

%\terms{Design, Algorithms, Performance}

%\keywords{Wireless sensor networks, media access control,
%multi-channel, radio interference, time synchronization}

%\acmformat{Zhou, G., Wu, Y., Yan, T., He, T., Huang, C., Stankovic,
%J. A., and Abdelzaher, T. F.  2010. A multifrequency MAC specially
%designed for  wireless sensor network applications.}

\begin{bottomstuff}
Author's adresses: C. Goll, Institut f\"ur Angewandte Mathematik,
Universit\"at Heidelberg;
T. Wick, The Institute for Computational Engineering and Sciences;
W. Wollner, Fachbereich Mathematik, Universit\"at Hamburg.
\end{bottomstuff}
                      

\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{introduction}
The \textit{Differential Equations and Optimization Environment} (\dope{}) 
provides a software toolkit to solve forward PDE
problems as well as optimal control problems constrained by a PDE. 
Its main feature is to give a unified interface to high level algorithms such as 
time stepping methods, nonlinear solvers and optimization routines. 
We aim that the user should only need to write those parts
of the code that are problem dependent while all invariant parts of the algorithms
should be reusable without any need for further coding.
In particular, the user should be able to switch between various different 
algorithms without the need to rewrite the problem dependent code, though he or she will
have to replace the algorithm object with an other one. 

The
solution of a broad variety of PDE is possible in other software
libraries (like in \deal{} \cite{deal}, dune \cite{dune} , 
or commercial solvers like Ansys \cite{ansys}) 
as well, but
\dope{} concentrates on a unified approach for both linear and nonlinear
problems by interpreting every PDE problem as nonlinear and applying a
Newton method to solve it. While \deal{} leaves much of the work and many
decisions to the user, \dope{} intends to be user-optimized by delivering
prefabricated tools which require from the user only adjustments connected
to his specific problem. The solution of optimal control problems with PDE
constraints is an innovation in the \dope{} framework.
The focus is on the numerical solution of both stationary and nonstationary
problems which come from different application fields, like elasticity and
plasticity, fluid dynamics, and fluid-structure interactions.

The \dope{} project is 
based on the \deal{} \cite{deal} finite element library which has been developed
 initially by W. Bangerth, R. Hartmann, and G. Kanschat \cite{deal}.
The authors acknowledge their past experience as well as discussions with 
the authors of the libraries 
Gascoigne/RoDoBo project, which was initiated by 
Roland Becker, Dominik Meidner,  and Boris Vexler \cite{rodobo}. 
From which some of the ideas to modularize the algorithms have arisen.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%The aim of \dope{} is to provide a software toolkit to solve forward PDE
%problems as well as optimal control problems constrained by PDE. The
%solution of a broad variety of PDE is possible in \deal{} as well, but
%\dope{} concentrates on a unified approach for both linear and nonlinear
%problems by interpreting every PDE problem as nonlinear and applying a
%Newton method to solve it. While \deal{} leaves much of the work and many
%decisions to the user, \dope{} intends to be user-optimized by delivering
%prefabricated tools which require from the user only adjustments connected
%to his specific problem. The solution of optimal control problems with PDE
%constraints is an innovation in the \dope{} framework.
%The focus is on the numerical solution of both stationary and nonstationary
%problems which come from different application fields, like elasticity and
%plasticity, fluid dynamics, and fluid-structure interactions.
%

At the present stage the following key features are supported by the library
\begin{itemize}
\item Solution of stationary and nonstationary PDEs in 1d, 2d, and 3d.
\item Various time stepping schemes (based on finite differences), 
  such as forward Euler, backward Euler,
  Crank-Nicolson, shifted Crank-Nicolson, and Fractional-Step-$\Theta$ scheme.
\item All finite elements of from \deal{} including hp-support.
\item Several examples showing the solution of several PDEs including
   Poisson, Navier-Stokes, Plasticity and fluid-structure interaction problems. 
\item Self written line search and trust region newton algorithms for the 
   solution of optimization problems with PDEs \cite{NoWr00}
\item Interface to SNOPT for the solution of optimization problems with PDEs and
  additional other constraints.
\item Several examples showing how to solve various kinds of optimization problems
  involving stationary PDE constraints.
\item Goal-oriented mesh adaptation with the dual-weighted residual method.
\item Different spatial triangulations for control and state variables.
\end{itemize}

The article is organized as follows. In Section
\ref{detailed_description} 
 
%The rest of this document is structured as follows: We start with an introduction in
%Chapter~\ref{chap:intro} where you will learn what is needed to run {\tt \dope{}}. 
%Further you will learn what problems we can solve and how all the different classes 
%work together for this purpose. This should help you figure out what the different classes
%do if you are in need of writing your own algorithm.
%
%Then assuming that you can work to your satisfaction with the algorithms already implemented
%we will show you how to create your own running example in Chapter~\ref{chap:howtoex}.
%This will be followed by a detailed description of all examples already shipped with 
%the library. You can find the examples for the solution of PDEs in Chapter~\ref{PDE}
%and those for the solution of optimization problems with PDEs in Chapter~\ref{OPT}.
%
%These notes conclude with a section that explains how we do automated testing of the 
%implementation in Chapter~\ref{chap:test}. This chapter will be of interest only if you 
%are trying to implement some new features to the library so that you can check that 
%the new code did not break anything.
%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Detailed Description of the Main Features}
\label{detailed_description}
%\todo{Aus der Sicht des Users anhand eines konkreten Beispiels beschreiben}
%\todo{Einfaches Beispiel nehmen}
%\todo{erwaehnen, dass wir alles immer nicht-linear betrachten}
%\todo{Aussehen eines typischen PDE und Opt loop und deren Gemeinsamkeiten
%erklaeren. Vielleicht mir Pseudocode}
This library is designed to allow easy implementation and numerical solutions 
of problems involving partial differential equations (PDEs). 
In particular, we remove all tedious routine implementation needed in 
\deal{} by introducing appropriate classes that take care of all the 
problem independent implementation while leaving only the problem specific 
part to the user. To show how this is designed we will, in the sequel, 
describe the reasoning first for a simple stationary PDE and then show
how this idea extends to non stationary problems as well as to optimization
problems with PDE constraints. 

\subsection{Solving of PDEs}
\subsubsection{Stationary problems}
For the start we consider a prototypical problem given by the solution of 
a stationary PDE, which we assume to be given in weak form.
In abstract notation it reads; find some $u$ in an appropriate set
such that
\begin{align}\label{eq:prototype_weak}
a(u)(\phi) = f(\phi) \quad \forall \phi \in V,
\end{align}
with some suitable space $V$ for the test functions and a 
right hand side $f$.
To illustrate this further, we take the stationary 
incompressible Navier-Stokes equations in a domain $\Omega \subset \R^d$, 
i.e., $u = (v,p)$ and $\phi = (\phi_u,\phi_p)$ then
\begin{align}\label{eq:ns}
a(u)(\phi) = \nu(\nabla v, \nabla\phi_u) + (v \nabla v,\phi_u) + (p, \nabla \cdot \phi_u) + (\nabla \cdot v ,\phi_p)
\end{align}
for all $\phi \in V = H^1_0(\Omega;\R^d) \times L^2_0(\Omega)$.
The solution will be searched for in $V + (u_d,0)$ where $u_d$ is some 
continuation of the given Dirichlet boundary data.
Then typically we do not only want to calculate $u$ but more likely we are 
interested in one (or several) functionals depending on the solution, i.e., some numbers $J(u)$.
%For example, if $u$ is the solution of the Navier-Stokes equations \eqref{eq:ns}, we look for the Drag 
%\begin{align*}
%J(u)=\int
%\end{align*}

In order to solve this problem, i.e., calculate $J(u)$, we need to discretize 
the equation. In \dope, we are using finite elements to do this. This means we need to pick a 
subdivision $\mathcal T_h$, for instance into quadrilaterals,
of the domain $\Omega$ and a finite element. In the concrete case we could, 
for instance, take the $\mathcal Q_2/\mathcal Q_1$ Taylor-Hood element.
As it is clear, that the initialization of the unknowns, the local shape 
functions, removal of hanging node constraints, etc. always follows the 
same procedure, we define an object which takes the finite element (FE)
and the triangulation and takes care of all other things related with 
handling the finite element space $V_h$. We will refer, to 
this as the \texttt{SpaceTimeHandler}. It is then clear, that the simplest 
form of the constructor should have the following interface:
\begin{lstlisting}
  template<typename Triangulation, typename FE>
      void SpaceTimeHandler(Triangulation &, FE);
\end{lstlisting}
Next, one needs to solve the discrete equation
\begin{align}\label{eq:discrete_equation}
a(u_h)(\phi_h) = f(\phi_h) \quad \forall \phi \in V_h.
\end{align}
To this end one can employ a newton type method with some globalization 
like line-search. To do so, one needs to calculate the residual of the 
equation, as well as solving linearized equations for the calculation of 
the newton method and then employing some kind of globalization strategy.
This again will usually require the evaluation of the residual.

The evaluation of the residual will require the calculation of the integrals 
involved in the weak formulation of the problem. For example 
the $i$-th component of the residual, with respect to the given FE-basis 
$\phi_{h,i}$, will read as follows
\begin{align}\label{eq:residual_vector}
 a(u_h)(\phi_{h,i}) - f(\phi_{h,i}) = \sum_{K\in \mathcal T_h} \nu\int_K \nabla u, \nabla \phi_i\,dx + \ldots
 \end{align}
Again, we see that, except for the local element integrals, all 
calculations are independent from the concrete form of the PDE. 
Hence we define an object \texttt{Integrator}
that offers a method to calculate the residual given a user-defined 
object \texttt{pde} that implements the local element integrals, i.e.,
\begin{lstlisting}
  template<typename PROBLEM,typename VECTOR>
      void Integrator
             ::ComputeNonlinearResidual(PROBLEM& pde, 
                                        VECTOR & residual);
\end{lstlisting}
where \texttt{VECTOR} is one of the possible vector types given by \deal{}.
It is clear that we need to ensure that the integrator object has access
to the information stored in the \texttt{SpaceTimeHandler}
to correctly loop over all elements.
To solve the linearized systems, again, all that is left is the calculation
of the matrix corresponding to the linearized equation. To calculate this,
again we can define a method in the integrator that does exactly this provided
we have a user defined object \texttt{pde} that can evaluate the local 
integrals needed for assembling the matrix, i.e.,
\begin{lstlisting}
  template<typename PROBLEM,typename MATRIX>
      void Integrator
             ::ComputeMatrix(PROBLEM& pde, 
                             MATRIX & system_matrix);
\end{lstlisting}
where now \texttt{MATRIX} is one of the matrix types supported by \deal{}.
With this we can now define a nonlinear solver \texttt{NewtonSolver} 
for the solution of the discrete problem requiring the existence of the 
following function
\begin{lstlisting}
 template<typename LINSOLVE>
  template<typename PROBLEM, typename VECTOR>
      void NewtonSolver<LINSOLVE>
             ::NonlinearSolve(PROBLEM& pde, 
                              VECTOR & solution);
\end{lstlisting}
Where \texttt{LINSOLVE} denotes the solver that should be used to solve the 
linearized equations during the newton iteration.

Finally, we note that to compute the requested functional value 
all that is left is to evaluate the functional in the computed solution 
which can be done again using an appropriate integrator method.
Since the sequence of events sketched above is again independent of the 
exact problem we introduce another container around it which we call 
\texttt{StatPDEProblem} that then simply provides the user with the 
method
\begin{lstlisting}
      void StatPDEProblem::ComputeReducedFunctionals();
\end{lstlisting}
That combines all the necessary steps to calculate $J(u_h)$. 

Finally, we will need to have an object that is capable of providing all 
the necessary functionality required from the template argument 
\texttt{PROBLEM} in all of the above. We provide a wrapper named
\texttt{PDEProblemContainer} collecting all the problem specific information 
like the description of the PDE and the functional, the boundary values, etc. 
Although, having such an object instead of directly giving these informations
to the \texttt{StatPDEProblem} seems like a nuicance at the moment, we will 
see that it is of greater interest for time-dependent problems or 
optimization problems in what follows in Section~\ref{sec:timedep} and
Section~\ref{sec:opt} respectively. 

\begin{remark}
In fact, the above constructors are not exactly what is implemented in \dope{}.
This is due to the fact, that for instance 
there are several different sparsity patterns available in 
\deal{} which the user should be able chose. Thus it needs to be 
given to the \texttt{SpaceTimeHandler}. However, to keep the 
presentation clear we refrained from including these details above and in
what follows.
\end{remark} 

In the next section we will now sketch the way a user needs to implement the
user-dependent data as the local cell integrals and the initialization of the
objects described above.
\subsubsection{Problem dependent implementation of stationary PDE problems}
To solve a stationary PDE problem, the user has to provide some code which can roughly be divided into the following main sections:
\begin{description}
\item[Discretization] Specify what kind of triangulation, finite element, quadrature rule, etc. we want to use.
\item[Problem-data] Define the weak form, the corresponding matrices, the functionals as well as the boundary conditions. With exception of the boundary conditions, we have to specify all this only cell-wise, \dope{} handles the rest for us.
\item[Solvers] Which (non-)linear solver should we use? 
\mymarginpar{besser algorithmen?}
\item[Miscellaneous] ParameterReader? Outputhandler etc.
\end{description} 
[Hier eventuell auf Unterschied zw. blosser Objekterstellung und dem tatsaechlichen 'Programmieren' fuer localpde etc. eingehen.]

We describe now a program designed to compute a value $J(u)$, where $u=(v,p)$ is the solution of the Navier-Stokes equations \eqref{eq:ns} on the domain $\Omega$ as seen in figure~\ref{fig:example_ns} with  $f=0$, and $J$ is the drag-force of the enclosed circle. We assume given Dirichlet data for the velocity $v$ on the boundary $\Gamma_{D}=\Gamma_{in}\cup\Gamma_{wall}\cup\Gamma_{circ}$. This is the Benchmark-Case 2D-1 from \cite{TuSchae96}, see there for further details.
%Additionally, for given inflow $v_{\operatorname{in}}$ we set  boundary conditions 
%v = v_{\operatorname{in}} \text{ on } \Gamma_{in}\text{ and }v = 0  \text{ on } \Gamma_{wall}.
\begin{figure}[h]
\centering
\resizebox{0.5\textwidth}{!}{\input{Pictures/example_ns}}
\caption{Flow around a cylinder with 
circle-center $C=(0.2,0.2)$ and radius $r=0.05$.}
\label{fig:example_ns}
\end{figure}

We split the program into the parts \texttt{main.cc}, \texttt{functionals.h} and \texttt{localpde.h}. The \texttt{main.cc}-file is responsible for the declaration of various objects which have mostly to do with the \textit{discretization}, the \textit{solvers} and the general \textit{program sequence}, whereas the other two contain most of the problem-data -- especially the cell-wise contributions of the weak form, the right hand side and the functional. We give a brief explanation on every file in the following.

\paragraph{\texttt{main.cc}}
In this file we gather the basic components that are necessary for the solution process of a (stationary) partial differential equation. The structure of the program is basically the same for every equation under consideration, what changes is typically just the \textit{kind} of  finite element or the linear solver.\marginpar{Bin mit diesen Saetzen nicht so ganz zufrieden, mir faellt aber gerade nichts besseres ein. Mir geht es hier darum, dass ich nicht wirklich was programmieren, sondern eher etwas auswaehle, wohingegen in den anderen files tatsaechlich was zu tun ist.}  
%The implementation of problem related data happens somwhere else, here we basically just pick together things like th

After the usual preamble, in which we include the necessary header-files from \deal{}, \dope{} and our own problem (i.e. \texttt{localfunctional.h} and \texttt{localpde.h}), we start by defining an instance of a \texttt{ParameterReader}-object, which handles run-time parameter.
\begin{lstlisting}
   ParameterReader pr;
\end{lstlisting}
In a text-file we might specify some problem-related parameters (for instance the viscosity $\nu$), but also general parameters for (non)-linear solvers and the output of computed data. 
After that, we create a triangulation of the domain $\Omega$ named \texttt{triangulation}.
%This is done exactly as in \deal{}, so we can choose between several possibilities: We could explicitly create a grid by providing a list of vertices and cells, read in a triangulation via \texttt{dealii::GridIn}-class or use the \texttt{dealii::GridGenerator}, which offers common domains like hypercubes or hyper-balls.

Next, we create some quadrature rules (for the evaluation of integrals over cells and faces) and a finite element appropriate for the PDE at hand. We choose a gaussian quadrature of order three and the previosly mentioned Tayler-Hood element. \marginpar{Wie klar machen, dass vieles von deal.II uebernommen und nicht selbst geschrieben?}
\begin{lstlisting}
  QGauss<2> quad_formula(3);
  QGauss<1> face_quad_formula(3);
  FESystem<2> finite_element(dealii::FE_Q<2>(2), 2,
                             dealii::FE_Q(1), 1);
\end{lstlisting}
%IntegratorDataContainer<VECTOR, 2> idc(quad_formula,
%                                         face_quad_formula);
%The \texttt{IntegratorDataContainer} class just makes the constructor interface of 
Then, the \texttt{LocalPDE} and \texttt{LocalFunctional} objects come into play.
\begin{lstlisting}
LocalPDE<VECTOR> local_pde;
LocalFunctional<VECTOR> local_functional;
\end{lstlisting}
These hold the information of the PDE and functional under consideration. Further explication is given below because
the definition of this classes is done spererately in \texttt{localpde.h} resp.   \texttt{localfunctional.h}.

In the next step, we define an object of type \texttt{SpaceTimeHandler}, which handles all the things connected with the triangulation as well as the finite element space. This class is also capable of organizing degrees of freedom in time-dependent problems, hence the name. 
\begin{lstlisting}
  SpaceTimeHandler<TRIANGULATION, FE> dof_handler(triangulation,
                                                  finite_element);
\end{lstlisting}
There exist different versions of this class for forward as well as optimization problems. 

Now we have everything at hand to create an instantiation of type \texttt{PDEProblemContainer}. This basically represents the disrectized problem, and bundles things like boundary conditions, the PDE, the functional and the discretization. First, we give the constructor the \texttt{local\_pde} and the \texttt{dof\_handler}.
\begin{lstlisting}
  PDEProblemContainer<LocalPDE> prob_container(local_pde,
                                               dof_handler);
\end{lstlisting}
After that, we add the functional under consideration and, because it is a boundaryfunctional, we specify the part of the boundary on which the functional operates (this is done via a 'boundarycolor').
\begin{lstlisting}
  prob_container.AddFunctional(&local_functional);
  prob_container.SetBoundaryFunctionalColors(1);
\end{lstlisting}
Next, we incorporate the dirichlet data, which is given by the class \texttt{DirichleData}. Then we have to tell the \texttt{prob\_container} for which components and boundaries we prescribe the dirichlet conditions. This is done via a boundary-color (0 stands for $\Gamma_D$) and a \texttt{std::vector<bool> comp\_mask = (true, true, false)}.
\begin{lstlisting}
  DirichletData dd;
  prob_container.SetDirichletBoundaryColors(0, comp_mask, dd);
\end{lstlisting}
Now we create the object which steers the whole solution process, the previosly mentioned \texttt{StatPDEProblem}. It takes care of solving the discretized equation and evaluating the given functionals. The class depends actually on some template-parameters, so for the sake of abbreviation, we defined a typedef at the beginning of the \texttt{main.cc}-file.
\begin{lstlisting}
typedef StatPDEProblem<NEWTONSOLVER,
           PDEProblemContainer<LocalPDE>, VECTOR, 2> SSOLVER;
\end{lstlisting}
Here, \texttt{NEWTONSOLVER} itself is an abbreviation of
\begin{lstlisting}
typedef NewtonSolver<LINEARSOLVER, VECTOR, 2> NEWTONSOLVER;
\end{lstlisting}
The first template parameter of \texttt{NewtonSolver} describes which linear solver we use in this example. We opted for a direct solver, so: 
\begin{lstlisting}
typedef DirectLinearSolverWithMatrix<MATRIX,
            VECTOR, 2> LINEARSOLVER;
\end{lstlisting}
With the type settled, we create the object \texttt{solver}, which needs the discretization (represented here by the \texttt{prob\_container}), the parameter reader as well as the quadrature rules.
\begin{lstlisting}
  SSOLVER solver(prob_container, pr, quad_formula, face_quad_formula);
\end{lstlisting}
%Finally, the output handler is initialized via
%\begin{lstlisting}
%  P.RegisterOutputHandler(&out);
%  solver.RegisterOutputHandler(&out);
%\end{lstlisting}
Finally, the programm is started by
\begin{lstlisting}
  solver.ReInit();
  solver.ComputeReducedFunctionals();
\end{lstlisting}

\paragraph{\texttt{localpde.h}}
We shall now give an overview to the implementation of the specific form of the PDE. 

%\marginpar{Rekapitulierung des Newton-Verfahrens?}
Let $N$ be the number of degrees of freedom of our discretization and $\Set{\phi_{h,i}|1\leq i \leq N}$ be a given FE-Basis. As stated in [sectionref], to solve the discrete equation \eqref{eq:discrete_equation} we need the residual, i.e. the vector
\begin{align}\label{eq:discrete_residual}
\left(a(u_h)(\phi_{h,i})-(f,\phi_{h,i})\right)_{i=1}^N,
\end{align}
and the Jacobi-matrix of the weak form, i.e.
\begin{align}\label{eq:discrete_matrix}
\left(\nabla a(u_h)(\phi_{h,j},\phi_{h,i})\right)_{i,j=1}^N.
\end{align}
Now all we have to supply here are the cell-wise contributions to these terms, the \texttt{Integrator} takes care of assembling \eqref{eq:discrete_residual} and \eqref{eq:discrete_matrix}.

To this end, we define a class \texttt{LocalPDE} which provides the three methods
\texttt{CellEquation}, \texttt{CellRightHandSide} and \texttt{CellMatrix}. The implementation of the terms works by and large as in \deal{}. We show the basic structure of these methods using the example of \texttt{CellEquation}.

\begin{lstlisting}
  void CellEquation(const CellDataContainer<2>& cdc,
                    VECTOR &local_cell_vector)
    {
      const auto& fe_values = cdc.GetFEValuesState();
      unsigned int n_dofs_per_cell = cdc.GetNDoFsPerCell();
      unsigned int n_q_points = cdc.GetNQPoints();
\end{lstlisting}
 The \texttt{CellDataContainer} contains all the information we need to compute the cell-contributions (things like number of quadrature points, number of degrees of freedom on the cell, the \texttt{dealii::FEValues}-objects, etc.).
%  \begin{lstlisting}
%      _uvalues.resize(n_q_points,Vector<double>(3));
%      _ugrads.resize(n_q_points,vector<Tensor<1,2> >(3));
%      cdc.GetValuesState("last_newton_solution", _uvalues);
%      cdc.GetGradsState("last_newton_solution", _ugrads);
%  \end{lstlisting}
  \begin{lstlisting}
     cdc.GetValuesState("last_newton_solution", uvalues);
     cdc.GetGradsState("last_newton_solution", ugrads);
 \end{lstlisting}
 In these two lines, we load the (gradient of the) solution of the last newton iteration in all the quadrature points on the cell into the two vectors \texttt{uvalues} and \texttt{ugrads}.

In the next lines, we loop over the quadrature points and the number of DoFs of the cell. In the innermost loop, we evaluate the weak form tested with $\phi_{i,h}$ (represented by \texttt{phi\_i\_grads\_v}) on the cell with the help of the previosly selected quadrature formula. 
%     const FEValuesExtractors::Vector velocities(0);
%     const FEValuesExtractors::Scalar pressure(2); 
 \begin{lstlisting}
    for(unsigned int q_point = 0; q_point < n_q_points; q_point++)
    {
      //initialize phi_i_grads_v etc.
      Tensor<2,2> vgrads;
      vgrads[0]= ugrads[q_point][0]; 
      vgrads[1]= ugrads[q_point][1];
      for (unsigned int i=0;i<n_dofs_per_cell;i++)
        local_cell_vector(i) += ( _nu 
                                * vgrads * phi_i_grads_v 
                                + //all the other terms)
                                * state_fe_values.JxW(q_point);
    }
\end{lstlisting}
\dope{} takes now care of the distribution of the local cell contributions into  the vector of the residual \eqref{eq:residual_vector}. The methods \texttt{CellRightHandSide} and \texttt{CellMatrix} follow the same structure as 
\texttt{CellEquation}, so we do not go into the details here.
% [CellEquation]
% 
% \begin{lstlisting}
%   void CellRightHandSide(const CellDataContainer<2>& cdc,
%                          dealii::Vector<double> &local_cell_vector,
%                          double scale);
% \end{lstlisting}
% 
% \begin{lstlisting}
%   void CellMatrix(const CellDataContainer<2>& cdc,
%                   dealii::FullMatrix<double> &local_entry_matrix);
% \end{lstlisting}
% The PDE under consideration is nonlinear, so let us briefly recapitulate manner such that for solving 
% the Laplace problem the following nonlinear step is necessary to recapitulate:
% Find $\delta u\in V$:
% \[
% (\nabla \delta u, \nabla \phi) = -(\nabla u, \nabla \phi) 
% \]
% and $u^{n+1} = u^n + \delta u$ for $n=1,2,3,ldots$.
% Therefore, the implementation reads for the right hand side:
% \begin{lstlisting}
%    void CellEquation(...)
%     {
%       // implement (\nabla u, \nabla \phi) 
%     }
% \end{lstlisting}
% Specifically, the inner loops reads
% \begin{lstlisting}
%    for (all quadrature points per cell q)
%       {
%         Tensor<2, 2> ugrads; // solution vector
%  
% 	for (all dofs per cell i)
%         {
% 	  const Tensor<2, 2> phi_i_grads_u; // test function
% 
%           local_cell_vector(i) += scale * 
%             scalar_product(ugrads, phi_i_grads_u) *
% 	    state_fe_values.JxW(q_point);
%         }
%       }
% \end{lstlisting}
% For the left hand side, we need to implement the Jacobian matrix:
% \begin{lstlisting}
%    void CellMatrix(...)
%     {
%       // implement  (\nabla \delta u, \nabla \phi)
%     }
% \end{lstlisting}
% Specifically,
% \begin{lstlisting}
%       for (all quadrature points per cell q)      
%         for (all dofs per cell i)    
%           for (all dofs per cell j)
%           {
%             local_entry_matrix(i, j) += 
%               scalar_product(phi_grads_u[j], phi_grads_u[i]) * 
%               state_fe_values.JxW(q_point);
%           }
% \end{lstlisting}
% The integration of the equation for each DoF and each quadrature point on each
% cell is then done 
% in the \texttt{templates/integrator.h} function. Finally, as usually in 
% finite element computations, this leads to a discrete system. Since
% we treat each problem with a Newton method, within each Newton step, the 
% following linear system must be solved:
% \[
% A\delta u = b
% \]
% in which $A$ is specified by \texttt{CellMatrix(...)} and 
% $b$ by \texttt{CellEquation(...)}. The vector $\delta u$ denotes the solution to the 
% present Newton step:
% \[
% u^n = u^{n-1} + \omega \delta u
% \]
% with a line search parameter $\omega\in (0,1]$.

\paragraph{\texttt{localfunctional.h}}
The implementation of the boundary-functional $J$ follows the outline of the computation of the cell-residual in \texttt{localpde.h}. However, there are two main differences. First, we do not have to specify the method \texttt{CellEquation}, but \texttt{BoundaryValue} instead. This is due to the fact that we consider a boundary-functional in this example, and so we have to specify the value of the functional not cell-wise but face wise (for the faces that lie on $\Gamma_{circ}$). The second difference is that as we only want to evaluate a functional and not a residual-vector, we just loop over the quadrature points and not over the degrees of freedom on the face.
\begin{lstlisting}
 double
 BoundaryValue(const FaceDataContainer<2>& fdc)
  {
    //same as before, get n_q_points etc.
    fdc.GetFaceValuesState("state", ufacevalues);
    fdc.GetFaceGradsState("state", ufacegrads);
\end{lstlisting}
Notice that we get here the values of the computed solution by giving the string "state".
\begin{lstlisting}
    for(unsigned int q_point = 0; q_point < n_q_points; q_point++)
      erg += -1. * ( _nu * ufacegrads[q_point][0]
                * state_fe_face_values.normal_vector(q_point)
                + //other terms)        
                * state_fe_face_values.JxW(q_point);
    return erg;
  }
\end{lstlisting}

% The target functional 
% is now implemented in \texttt{functional.h} and 
% treats a point evaluation:
% \begin{lstlisting}
%   double PointValue(...)
%    {
%     Point<2> p1(0.5, 0.5);
%     Vector<double> tmp_vector(2);
%     // more stuff is necessary here
%     VectorTools::point_value (...);
%     double x = tmp_vector(0);
% 
%     return x;
%    }
% \end{lstlisting}




% TWick:
% To solve the problem, we need a configuration (a mesh), eventually 
% a diffusion parameter, a finite element, a quadrature rule,
% a linear solver (here the CG solver), and some output such as
% a graphical solution and eventually some measurement functional.
% Each of those routines are written in the \texttt{main.cc} file. 
% We start by including necessary files both the \dope{} library and
% the \deal{} software:
% \begin{lstlisting}
%   #include "pdeproblemcontainer.h" etc. ...
% \end{lstlisting}
% In the \texttt{main} function, the following steps need to be done. First, 
% the parameter reader for runtime parameters might be initialized. In a parameter
% file the user might specify material parameters for the concrete PDE, but also
% general parameters for nonlinear and linear solvers, and output-related 
% aspects.
% 
% A linear finite element in two dimensions and two components is 
% initialized:
% \begin{lstlisting}
%   FESystem<2> state_fe(FE_Q<2>(1), 2);
% \end{lstlisting}
% and a quadrature rule of order three is used to approximate the 
% integrals:
% \begin{lstlisting}
%   QGauss<2> quadrature_formula(3);
% \end{lstlisting}
% Then, the \texttt{LocalPDE} object comes into play. This is an quite 
% important feature of \dope{} because it allows for easy implementation 
% of the variational formulation. Specific explication is given below because
% the implementation is separated in \texttt{localpde.h}.
% Afterwards, a \texttt{LocalPointFunctional} is declared. As for the PDE, the 
% implementation is done in another file, namely \texttt{localfunctional.h}.
% 
% Generically, each problem in \dope{} is considered to be time-dependent and nonlinear because
% these are the 'real' world problems. Therefore, (even for the linear and stationary Laplace equation),
% we have to declare a (pseudo) time:
% \begin{lstlisting}
%   std::vector<double> times(1, 0.);
% \end{lstlisting}
% Then, the spatial mesh (here the unit square) is created and three-times globally-refined:
% \begin{lstlisting}
%   GridGenerator::hyper_cube(triangulation, 0, 1);
%   triangulation.refine_global(3);
% \end{lstlisting}
% A major component which organizes the whole solution process (independent from 
% the problem!) is the 
% \begin{lstlisting}
%   MethodOfLines_StateSpaceTimeHandler<...> dof_handler (...);
% \end{lstlisting}
% This method handles all dofs in space and time and different versions exist
% for forward as well as optimization problems.
% 
% Afterwards, the problem (here the Laplace PDE) is given to the \texttt{dof_handler} via
% \begin{lstlisting}
%   OP P(local_pde, dof_handler);
% \end{lstlisting}
% It remains to declare boundary conditions for the problem under consideration. 
% Let's simply take zero Dirichlet conditions on the boundary:
% \begin{lstlisting}
%   std::vector<bool> comp_mask(2);
% 
%   comp_mask[0] = true;
%   comp_mask[1] = true;
% 
%   DOpEWrapper::ZeroFunction<2> zf(2);
%   SimpleDirichletData<VECTOR, 2> DD1(zf);
% 
%   P.SetDirichletBoundaryColors(0, comp_mask, &DD1);
% \end{lstlisting}
% Next, the solver for the linear equations needs to be specified:
% \begin{lstlisting}
%   SSolver solver(&P, "fullmem", pr, idc);
% \end{lstlisting}
% Finally, the output handler is initialized via
% \begin{lstlisting}
%   P.RegisterOutputHandler(&out);
%   solver.RegisterOutputHandler(&out);
% \end{lstlisting}
% Finally, the programm is started with:
% \begin{lstlisting}
%   solver.ReInit();
%   out.ReInit();
%   out.Write(outp, 1, 1, 1);
%   solver.ComputeReducedFunctionals();
% \end{lstlisting}
% After explaining the basic compononents that are necessary (and always the same in \dope{}) 
% for all  (linear and stationary) partial differential equations, we shall give 
% an overview to the implementation of the specific form of the PDE. 
% Beside specification of boundary conditions, the form of the local PDE depends 
% on the concrete problem under consideration. 
% This step is done in the \texttt{localpde.h} file. As already explained,
% each PDE is treatet in a nonlinear manner such that for solving 
% the Laplace problem the following nonlinear step is necessary to recapitulate:
% Find $\delta u\in V$:
% \[
% (\nabla \delta u, \nabla \phi) = -(\nabla u, \nabla \phi) 
% \]
% and $u^{n+1} = u^n + \delta u$ for $n=1,2,3,ldots$.
% Therefore, the implementation reads for the right hand side:
% \begin{lstlisting}
%    void CellEquation(...)
%     {
%       // implement (\nabla u, \nabla \phi) 
%     }
% \end{lstlisting}
% Specifically, the inner loops reads
% \begin{lstlisting}
%    for (all quadrature points per cell q)
%       {
%         Tensor<2, 2> ugrads; // solution vector
%  
% 	for (all dofs per cell i)
%         {
% 	  const Tensor<2, 2> phi_i_grads_u; // test function
% 
%           local_cell_vector(i) += scale * 
%             scalar_product(ugrads, phi_i_grads_u) *
% 	    state_fe_values.JxW(q_point);
%         }
%       }
% \end{lstlisting}
% For the left hand side, we need to implement the Jacobian matrix:
% \begin{lstlisting}
%    void CellMatrix(...)
%     {
%       // implement  (\nabla \delta u, \nabla \phi)
%     }
% \end{lstlisting}
% Specifically,
% \begin{lstlisting}
%       for (all quadrature points per cell q)      
%         for (all dofs per cell i)    
%           for (all dofs per cell j)
%           {
%             local_entry_matrix(i, j) += 
%               scalar_product(phi_grads_u[j], phi_grads_u[i]) * 
%               state_fe_values.JxW(q_point);
%           }
% \end{lstlisting}
% The integration of the equation for each DoF and each quadrature point on each
% cell is then done 
% in the \texttt{templates/integrator.h} function. Finally, as usually in 
% finite element computations, this leads to a discrete system. Since
% we treat each problem with a Newton method, within each Newton step, the 
% following linear system must be solved:
% \[
% A\delta u = b
% \]
% in which $A$ is specified by \texttt{CellMatrix(...)} and 
% $b$ by \texttt{CellEquation(...)}. The vector $\delta u$ denotes the solution to the 
% present Newton step:
% \[
% u^n = u^{n-1} + \omega \delta u
% \]
% with a line search parameter $\omega\in (0,1]$.
% 
% 
% The target functional 
% is now implemented in \texttt{functional.h} and 
% treats a point evaluation:
% \begin{lstlisting}
%   double PointValue(...)
%    {
%     Point<2> p1(0.5, 0.5);
%     Vector<double> tmp_vector(2);
%     // more stuff is necessary here
%     VectorTools::point_value (...);
%     double x = tmp_vector(0);
% 
%     return x;
%    }
% \end{lstlisting}




\subsubsection{Nonstationary problems}\label{sec:timedep}
To describe the solution of nonstationary 
PDEs, we consider a time-dependent semi-linear form
Let $I:=[0,T]$ be a time interval with end time point value $T$.
To find some $u$ in a weak form, we define
\[
\int_I a(u)(\phi) = \int_I f(phi) \quad \forall\phi\in X,
\]
with some suitable Bochner space $X$.  As model problem,
we consider the nonstationary Navier-Stokes equations
in a domain $\Omega\in\mathbb{R}^d$. Find: 
$(v,p)\in X$ with
\[
\int_I \bigl[ (\partial_t v, \phi)
+ \nu (\nabla v, \nabla \phi) + (v\cdot\nabla v, \phi)
- (p,\nabla\cdot \phi)
+ (\nabla\cdot v, \chi)\bigr] \, dt
+ (v(0) - v^0, \phi(0))
= \int_I (f,\phi) \, dt 
\]
for all $\phi:= (\phi, \chi) \in X$ with
\[
X:= \bigl\{ 
(v,p) | v\in L^2(I,H_0^1(\Omega)^d , 
\partial_t v\in L^2(I, L^2(\Omega)^d), 
p\in L^2(I,L^2(\Omega)\setminus\mathbb{R} \bigr\}.
\]
As for stationary problems, the goal is to compute
some target functional $J(\cdot)$ which is now possibly 
time-dependent. To organize the discretization 
process, we need to perform spatial and temporal 
discretization. This is again done via
a global object that treats the routines
in DOpElib:
\begin{lstlisting}
  template<typename Triangulation, typename FE, typename times>
      void MethodOfLines_SpaceTimeHandler(Triangulation &, FE, times);
\end{lstlisting}
Spatial discretization is the same
as discussed previously, and thus, we briefly demonstrate
routines to perform temporal integration in the following. 

\subsubsection{Problem-dependent 
implementation of nonstationary problems}
\label{sec:timedep:implementation}
We explain in more detail the temporal discretization
and specific issues of its implementation. 
To keep the presentation easy, we abuse notation 
by neglecting
all material coefficients
and give formal-related idea based on the weak 
form of the Navier-Stokes equations:
Find $(v,p)$ such that
\begin{align*}
(\partial_t v,\phi) 
+ (\nabla v, \nabla \phi)
+ (v\cdot\nabla v,\phi)
-(p,\nabla\cdot \phi)
+(\nabla\cdot v, \chi)
=(f,\phi).
\end{align*}
Temporal discretization using the One-step-$\theta$ scheme reads:
Given the old timestep solution $(v^n,p^n)$, 
find $(v^{n+1}, p^{n+1})$ (and multiplication 
through by the timestep $k$):
\[
(v^{n+1} - v^{n}, \phi)
+ k\theta (\nabla v^{n+1}, \nabla \phi)
+ k\theta (v^{n+1}\cdot\nabla v^n + 
  v^{n}\cdot\nabla v^{n+1},\phi)
- k (p^{n+1},\nabla\cdot \phi)
+ (\nabla\cdot v^{n+1}, \chi)
= k\theta (f^{n+1},\phi) + k(1-\theta) (f^{n},\phi)
- k(1-\theta) (\nabla v^{n}, \nabla \phi) 
\]
The concrete choice of $\theta$ leads to a
specific time stepping scheme. For instance,
$\theta = 0.5$ gives the Crank-Nicolson scheme,
\begin{lstlisting}
   CrankNicolsonProblem<...>
\end{lstlisting}


The pressure and incompressibily terms should be 
treated fully implicitly when time-discretizing 
the Navier-Stokes equations.
For this reason, the implementation is split up
into several items to account for fully implicit 
terms and remaining terms for which we need 
old timestep and present timestep values. 
Hence, in the local cell equation, a paramter
is used to distigugish these terms:
\begin{lstlisting}
  void CellEquation(...)
   {
      local_cell_vector(i) +=  scale * (\nabla v^{n+1}, \nabla \phi) + etc.

      local_cell_vector(i) +=  scale_ico * (-p^{n+1},\nabla\cdot v)
   }
\end{lstlisting}
Analogoues procedure is performed in the local 
cell matrix.

In addition to stationary problems, the implementation
of the time-derivative must be considered which is done
in 
\begin{lstlisting}
  void CellTimeEquation(...)
   {
     // implement (u^{n+1},\phi) 
   }
\end{lstlisting}
and it is done in a straight-forward way:
\begin{lstlisting}
  for (all quadrature points per cell q)
   {
     Tensor<1,2> u = ...;

     for (all dofs per cell i)
      {
        const Tensor<1,2> phi_i_u = ...;

        local_cell_vector(i) +=  
          scale * (u * phi_i_u) * 
          state_fe_values.JxW(q_point);
      }
   }
\end{lstlisting}
Here, the advantage is that \dope{} orders the terms in the timestepping
problems
such that only $(u^{n+1},\phi)$ must be implemented. 



\begin{remark}[Nonlinear terms in the time derivative]
However, if someone 
needs explicit input of the old timestep term, then he can use 
\begin{lstlisting}
  void CellTimeEquationExplicit (...)
   {
     // implement (u^{n+1},\phi) and (u^n,\phi)  
   }
\end{lstlisting}
\end{remark}

\begin{remark}[Fractional-Step-$\theta$-scheme]
The temporal discretization in this section 
is based on the One-Step-$\theta$-schemes. The library
offers in addition an implementation 
of the second-order and strongly $A$-stable 
Fractional-Step-$\theta$-scheme in which 
each time step is subdivided into three 
sub-timeintervals. 
\end{remark}





\subsection{Solving of optimization problems}\label{sec:opt}
Upgrading the framework for solving optimization problems
is described in this section. A prototypical problem reads:
\begin{align*}
\min\;&J(q,u) \\
  &\text{s.t.}\; a(q,u)(\phi) = 0 \quad \forall \phi\in V,\\
  &a \le q \le b,\\
  &g(q,u) \le 0,  
\end{align*}
where $u$ is a FE-function and $q$ can either be a FE-function or some 
fixed number of parameters, $a$ and $b$ are constraint bounds for the control $q$,
and $g(\cdot)$ is some state constraint.
As before, the main part is done in the \texttt{main} function there is no
great difference to the previous explications. However, 
since we utilize gradient-based optimization routines in the philosophy of
\cite{Troe99,HiKu01},
all derivatives must be implemented. All this information
must given to the \texttt{localpde.h} file. Herein, one has to 
implement the adjoint, tangent and adjoint Hession equations. 
The algorithmic parts are described in the literature \cite{BeMeVe06}.

Concretely, let us focus on the Laplace equation and 
the following optimization problem (taken from 
Example 2) in \texttt{Examples/OPT/StatPDE}:
\begin{align*}
\min_{(q,u)\in \mathbb R^3 \times H_0^1(\Omega; \mathbb R^2)} J(q,u) &=
\frac{1}{2} \sum_{i=0}^2 |(u-\overline u)(x_i)|^2 + \frac{\alpha}{2}\|q\|^2\\
\text{s.t.} (\nabla u,\nabla \phi) &= (f(q),\phi)\;\;\forall\,\phi \in H^1_0(\Omega; \mathbb R^2)
\end{align*}
on the domain $\Omega = [0,1]^2$, with
\begin{itemize}
\item the observation points
\begin{align*}
x_0 = (0.5, 0.5), \quad x_1 = (0.5, 0.25),\quad x_2 = (0.25, 0.25),
\end{align*}
\item the regularization parameter $\alpha = 0$, 
\item the right hand side
\begin{align*}
 f(q) &= q_0 \left(\begin{matrix}2\pi^2  \sin( \pi x) \sin(\pi y)\\0 \end{matrix}\right)\\
      &+ q_1 \left(\begin{matrix}5\pi^2  \sin( \pi x) \sin(2\pi y)\\0 \end{matrix}\right)\\
      &+ q_2 \left(\begin{matrix}0 \\8\pi^2  \sin(2\pi x) \sin(2\pi y)\end{matrix}\right)\\
\end{align*}
\item and the exact solution given by 
\begin{align*}
 \overline{q} &= \bigl(1;0.5;1\bigr)\\
 \overline{u}& = \left(\begin{matrix} \sin( \pi x)( \sin(\pi y)+0.5\sin(2\pi y))\\\sin(2\pi x) \sin(2\pi y) \end{matrix}\right).
\end{align*}
\end{itemize}
\begin{defi}[Constrained optimization]
\label{problem_constraint_optimization}
Minimize the cost functional $J(q,u)$ subject to the state equation
$a(q,u)(\phi) = 0$ for $(q,u) \in 
Q\times  \{v_D+{\cal X}\}$. 
\end{defi}
%
The constrained optimization problem  on the space $Q_d\times {\cal X}$ 
is reformulated into an unconstrained optimization problem on the
space $Q_d$. Therefore, we assume the existence of the solution operator  
$S:Q_d\rightarrow {v_D+{\cal X}}$ with a unique solution
$U=S(q)$. Herewith, we define the reduced cost functional
$j:Q_d\rightarrow \mathbb{R}$ by 
%
\begin{equation}
  \label{opt_reduced_functional}
  j(q) := J(q,S(q)) .
\end{equation}
%
Thus, the constrained optimization problem can be formulated by means
of  
%
\begin{defi}[Unconstrained optimization]
  \label{opt_reduced_problem}
  Minimize $j(q)$ for $q\in Q_d$.
\end{defi}
%
Newton's method to solve Problem~\ref{opt_reduced_problem} reads:
For $l=0,1,\ldots,$ solve
\begin{equation}
\label{opt_newton_method}
\begin{aligned}
j''(q^l)(\delta q , \tau q) &= -j'(q^l)(\delta q) 
\quad\forall\tau q\in Q_d, \\
q^{l+1} &= q^l + \omega\delta q,
\end{aligned} 
\end{equation}
with a line search parameter $\omega\in (0,1]$ which 
will are implemented in \texttt{reducednewtonalgorithm.h}.
Specifically, the residual and the Hessian of Newton's method 
\eqref{opt_newton_method}
can be computed with the help of the following two results:
\begin{proposition}[Residual of Newton's method]
\label{prop_newton_residual}
Let $q\in Q_d, u=S(q)\in {\cal X}$
and $z\in {\cal X}$ the dual solution be obtained after solving 
the first and second equation of the KKT system 
\eqref{opt_KKT_system}. 
Then the residual of Newton's method \eqref{opt_newton_method} 
is defined as
\begin{equation*}
j'(q)(\delta q) := {\cal L}'_{q}(q,u,z)(\delta q),
\end{equation*}
i.e., in explicit representation
\begin{equation*}
j'(q)(\delta q) := \alpha_T (q , \tau q)_Q - 
A_{q}'(q,u)(\tau q , z).
\end{equation*}
\end{proposition}
\begin{proof}
The proof uses standard techniques. Details can be found in  
\cite{BeMeVe06}.
\end{proof}
\begin{proposition}[Hessian of Newton's method]
  \label{prop_newton_hessian}
  Let $q\in Q_d, u=S(q)\in {\cal X}$ and $z\in {\cal X}$ and  $\delta
  q\in Q_d$ be given. Further, let $\delta u\in {\cal X}$ be the
  solution of the tangent problem 
  \[
  \delta u\in{\cal X},\quad 
  a_{u}'(q,u)(\delta u , \phi) 
  = -a_{q}'(q,u)(\delta q , \phi)  \quad\forall \phi\in {\cal
    X},
  \]
  and $\delta z\in {\cal X}$ the solution of the adjoint Hessian 
  problem  
  \[
  a_{u}'(q,u)(\phi, \delta z)
  = J''_{uu}(q,u)(\delta u, \phi)
  - a_{uu}''(q,u)(\delta u, \phi, z)
  - a_{qu}''(q,u)(\delta q , \phi, z)  \quad\forall \phi\in
  {\cal X}. 
  \]
 Then it holds  for all $\tau q\in Q_d$:
  \[
  j''(q)(\delta q, \tau q):= 
  \alpha_T (\delta q , \tau q)_Q -
  a_{qq}''(q, u)(\delta q, \tau q , z) -
  a_{uq}''(q,u)(\delta u, \tau q , z) -
  a_{q}'(q,u)(\tau q , \delta z).
  \]
\end{proposition}
\begin{proof}
  For the proof this statement (including its time-dependent version), we refer to 
  Becker et al. \cite{BeMeVe06}.
  The stationary version of this proposition is easily derived by neglecting 
  all time derivatives, which concludes the assertion. 
\end{proof}
The implementation of all previous terms 
is realized in the \texttt{localpde.h} file.
As an example, we examine the adjoint 
\begin{equation}
  \label{opt_KKT_system}
  \begin{aligned}
    a_{u}'(q,u)(\phi , z) &= J'_{u}(q,u)(\phi) & \forall \phi&\in {\cal X},
  \end{aligned}
\end{equation}

The implementation it split into equation terms, i.e., 
\begin{lstlisting} 
  void CellEquation_U(...)
   {
     // implement (\nabla \phi, \nabla z)
   }
\end{lstlisting}
and functional terms, i.e.,     
\begin{lstlisting} 
  virtual void PointValue_U(...)
      {
        // implement here the derivative of 
        // the point cost functional
      }
\end{lstlisting}
All remaining terms of the previous two propositions 
are implemented in the same manner.

Afterwards, it remains to use an appropriate 
optimization algorithm in order to solve the 
problem. At present we offer a selection of algorithms that solve the reduced optimization 
problem where the PDE constraint has been eliminated as explained previously.
\begin{itemize}
\item \texttt{opt\underline{ }algorithms/reducedalgorithm.h} An interface for all 
  optimization problems in the reduced formulation. It offers some test functionality
  to assert that the derivatives of the problem are computed correctly.
\item \texttt{opt\underline{ }algorithms/reducednewtonalgorithm.h}
  A line-search Newton algorithm using a cg method to invert the reduced hessian. 
  Implementation ignores any additional constraints.
\item \texttt{opt\underline{ }algorithms/reducedtrustregionnewton.h}
  A trust region Newton algorithm using a cg method to invert the reduced hessian.
  Implementation ignores any additional constraints.
\item \texttt{opt\underline{ }algorithms/reduced\underline{ }snopt\underline{ }algorithm.h}
  An algorithm to solve reduced optimization problems with additional control constraints.
  ((reduced) state constraints are not yet implemented.)
\item \texttt{opt\underline{ }algorithms/reducednewtonalgorithmwithinverse.h}
  Line-search Newton algorithm that assumes there exists a method in the reduced problem
  that can invert the reduced hessian. (This usually makes sense only if there is no 
  PDE constraint.)
\item \texttt{opt\underline{ }algorithms/generalized\underline{ }mma\underline{ }algorithm.h}
  An implementation of the MMA-Algorithm for structural optimization using an augmented
  Lagrangian formulation for the subproblems. The subproblem is implemented using the 
  special purpose file
  \texttt{include/augmentedlagrangianproblem.h}.
\end{itemize} 




\subsection{Independent features}
In this final section, we shall give a brief summary of features 
that are applicable (in general) to all types of problems. Specifically,
\dope{} provides goal-oriented mesh refinement with the help of the 
Dual-Weighted-Residual (DWR) method \cite{BeRa96}. Here, a certain 
cost functional such as a point evaluation, line intergration or domain
integration is considered. Determining the lowest error between the 
(unknown) exact solution and its numerical approximation for lowest computational
cost is the main goal of the DWR method.

Moreover, \dope{} provides standard error estimators based on residual evaluation and 
a ZZ error estimator, i.e., measureing the smoothness of the discrete first derivatives.
The latter one is accessed via \deal{}. 

In addition, \dope{} provides multi-mesh procedures 
\todo{kann Winni hier etwas schreiben?}

Concerning temporal integration schemes, the library comes 
with various time stepping schemes (based on finite differences), 
such as the first-order forward Euler and first-order backward Euler scheme. 
To compute fully nonstationary processes, the second-order schemes
Crank-Nicolson (trapozoidal rule), 
shifted Crank-Nicolson (slight shift to the implicit side to maintain
global stability), 
and the Fractional-Step-$\Theta$ scheme, are implemented.






%\subsection{Problem description}
%In order to allow our algorithms the automatic assembly of all required 
%data we need to have some container which contains the complete problem 
%description in a common data format. For this we have the following 
%classes in \texttt{DOpEsrc/container}
%\begin{itemize}
%  \item \texttt{pdeproblemcontainer.h} Is used to describe  stationary PDE problems.
%  \item \texttt{instatpdeproblemcontainer.h} {\bf TODO is still missing but will be used for nonstationary problems.} This will be implemented once we have nonstationary optimization problems running to avoid error duplication in the coding process.
%  \item \texttt{optproblem.h} Is used to describe  OPT problems governed by 
%    stationary PDEs. 
%  \item \texttt{instatoptproblemcontainer.h} Is used to describe  OPT problems
%    governed by nonstationary PDEs. The only difference to the stationary case
%    is that we need to specify a time-stepping method.  
%  \item \texttt{interfaces/functionalinterface.h} This gives an interface 
%    for the functional $J(\cdot)$ and any other functional you may want to evaluate.
%    In general this can be used as a base class to write your own functionals 
%    in examples. We note that we only need to write the integrands on 
%    elements or faces the loop over elements will be taken care of in the integrator.
%    Specifically, derivatives are written therein, too.
%\end{itemize}
%In order to fill these containers there are two things to be done,
%first we need to actually write some data, for instance,
%the semilinear form $a(\cdot)(\cdot)$, a target functional $J(\cdot)$, etc.,
%which describe the problem. Then we have to select some numerical 
%algorithm components like finite elements, linear solvers $\ldots$.
%The latter ones should be written such that when exchanging these components
%none of the problem descriptions should require changes. 
%Note that it still may be necessary to write some additional descriptions, 
%e.g., if you solve the PDE with a fix point iteration you don't need derivatives
%but if you want to use Newton's method, derivatives are needed.
%
%We will start by discussing the problem description components implemented so far
%
%
%\subsection{Numeric components}
%These are the components from which a user needs to select some in order to actually 
%solve the given problem. They will not require any rewriting, but sometimes it is 
%advisable to write other than the default parameter into the param file for the 
%solution.
%
%\subsubsection{Space-time handler}
%First we need to select a method how to handle all dofs in space and time.
%\begin{itemize}
%\item \texttt{basic/spacetimehandler\underline{ }base.h} This class is used to define 
%  an interface to the dimension independent functionality of all space time dof handlers.
%  {\bf TODO: Beispiele geben}
%\item \texttt{basic/statespacetimehandler.h} Another intermediate interface class which adds 
%  the dimension dependent functionality if only the variable $u$ is considered, i.e., a 
%  PDE problem.
%\item \texttt{basic/spacetimehandler.h } Same as above but with both $q$ and $u$, i.e., for
%  OPT problems.
%\item \texttt{basic/mol\underline{ }statespacetimehandler.h} Implementation of a method of 
%  line space time dof handler for PDE problems. It has only one spatial 
%  dofhandler that is used for all time intervals.
%\item \texttt{basic/mol\underline{ }spacetimehandler.h} Same as above for OPT problems.
%  A separate spatial dof handler for each of the variables $q$ and $u$ is maintained 
%  but only one triangulation.
%\item \texttt{basic/mol\underline{ }multimesh\underline{ }spacetimehandler.h}
%  Same as above, but now in addition the triangulations for $q$ and $u$ can be refined
%  separately from one common initial coarse triangulation. Note that this will
%  in addition require the use of the multimesh version for integrator and 
%  face- as well as celldatacontainer.
%\end{itemize}
%Note that we use these for stationary problems as well, but then you don't have to specify
%any time information.
%
%\subsubsection{Container classes}
%Second you will need to specify some container classes to be used to 
%pass data between objects. At present you don't have much choice, but you may wish 
%to reimplement some of these if you need data that is not currently included in 
%the containers.
%\begin{itemize}
%\item \texttt{container/celldatacontainer.h} This object is used to pass data 
%  given on the current element (cell) of the mesh to the functions in PDE, functional, 
%  $\ldots$. 
%\item \texttt{container/facedatacontainer.h} This object is used to pass data 
%  given on the current face of the mesh to the functions in PDE, functional, 
%  $\ldots$. 
%\item \texttt{container/multimesh\underline{ }celldatacontainer.h} This is the same as the 
%  celldatacontainer, but it
%  is capable to handle data defined on an alternative triangulation.
%\item \texttt{container/multimesh\underline{ }facedatacontainer.h} This is the same as the
%  facedatacontainer, but it
%  is capable to handle data defined on an alternative triangulation.
%\item \texttt{container/integratordatacontainer.h} This contains some data that 
%  should be passed to the integrator like quadrature formulas and the above cell and 
%  face data container.
%\end{itemize}
%
%
%
%
%\subsection{Reduced problems (Solve the PDE)}
%At times it is nice to remove the PDE constraint in (OPT). 
%This is handled by so called reduced 
%problems (for algorithmic aspects we refer the reader to 
%\cite{BeMeVe06}). 
%This means that the reduced problem implicitly solves the PDE whenever required
%and eliminates the variable $u$ from the problem.
%\begin{itemize}
%\item \texttt{reducedproblems/statpdeproblem.h} This is used to remove the variable $u$ in 
%  a stationary PDE problem. This means that call the method \\
%  \texttt{StatPDEProblem::ComputeReducedFunctionals} will evaluate the functionals 
%  defined in the problem description, i.e., in \texttt{PDEProblemContainer}, in the 
%  solution of the given PDE.
%\item \texttt{reducedproblems/statreducedproblem.h} This eliminates $u$ from the OPT
%  problem with a stationary PDE.
%\item \texttt{reducedproblems/instatreducedproblem.h} The same as above but for a
%  nonstationary PDE. {\bf FIXME there is something wrong in this file see FIXME 
%    comment in the source.}
%\item \texttt{reducedproblems/voidreducedproblem.h} A wrapper file that eliminates $u$ 
%  if it is not present anyways. This is used so that we can use the same routines to 
%  solve problems that have no PDE constraint.
%\end{itemize}
%




%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\subsection{Interfaces to other software packages}
%Since DOpE uses as basis the software library \deal{}, all its interfaces
%to other packages can be accessed to. For instance, such libararies 
%are trilinos for with an algebraic multigrid method, MPI for a parallel
%solution of the problem.
%
%In addition DOpE itself has an interface to SNOPT.
%
%%\section{Documentation, Code Development, Webpage}
%%\label{documentation}
%%At the present step, the \dope{} project comes with 
%%an detailed documentation of all features and examples 
%%in pdf format and an detailed programming code 
%%documentation. 
%%
%%\todo{License? How to access to DOpE?}
%%\todo{Name of the website}
%%
%%In addition, the \dope{} test suite provides some regression tests. 
%%They are run to compare 
%%the output to previous outputs. This is useful (necessary) after 
%%changing programming code anywhere in the library. If a test
%%succeeds, everything is fine in the library. If not, you should not
%%check in your code into DOpE. Please make sure what is going wrong and WHY!
%%Every command is computed via a Makefile. 
%%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Applications}
\label{applications}
We present three numerical tests which demonstrate different
features of \dope{}:
\begin{itemize}
\item In the first numerical example, we consider 
goal-oriented mesh refinement with the help of the 
Dual-Weighted-Residual (DWR) method for the stationary Navier-Stokes equations.
\item The second example presents nonstationary fluid-structure 
interaction. The challenges for those kind of problems are the multi-domain
character of the coupled problem and the treatment of the coupling conditions.
The problem is formulated in a variational monolithically-coupled way which 
allows to consider goal-oriented mesh refinement and gradient-based optimization.
\item In the third numerical test, an optmization problem for structural mechanics
is discussed.
\end{itemize}

\subsection{Goal-oriented mesh refinement for Navier-Stokes}
In this example we consider a laminar flow around a cylinder in 2d. To be more precise, we are computing the benchmark 2D-1 from \cite{TuSchae96}. The computational domain is as depicted in figure~\ref{fig:example_ns}. We want to compute the drag force on the enclosed cylinder
\begin{equation}
c_D = \frac 1 {20} \int_{\Gamma_{circ}} \nu\partial_nu _1 - pn,
\end{equation}
with the normal $n$ and $\nu = 0.001$. To achieve an efficient computation of the quantity $c_D$, we employ goal-oriented mesh refinement with the help of the DWR-method, see \cite{BeRa96}.

\begin{itemize}
\item Bild Freiheitsgrade vs Fehler, global und 
\item Bild adaptive mesh, bild der Loesung (?)
\item eventuell kurz auf duale gleichung eingehen.
\end{itemize}

\subsection{Nonstationary Fluid-Structure Interaction}
In this example, the challenging benchmark FSI 2
proposed by Hron and Turek \cite{HrTu06b} is considered.
To solve this problem accurately, it is very important that 
the coupling conditions
\[
v_f = v_s \quad \text{and} \quad \sigma_f n_f = \sigma_s n_s, 
\]
namely, the continuity of velocities and continuity of normal stresses
are satisfied in each time step. This is achieved with the help of 
a monolithic coupling scheme (strong coupling).

The basic configuration is 
sketched in Figure \ref{fig:example_ns} at which an elastic beam is attached 
behind the rigid cylinder. 
The computational domain has length $L=2.5m$ and height $H=0.41m$. The circle center
is positioned at $C=(0.2m,0.2m)$ with radius $r=0.05m$. The elastic beam has length
$l=0.35m$ and height $h=0.02m$. The right lower end is positioned at 
$(0.6m,0.19m)$, and
the left end is attached to the circle. 

%\begin{figure}[h]
%\centering
%\input{Pictures/pic_12}
%\caption{Flow around cylinder with elastic beam with 
%circle-center $C=(0.2,0.2)$ and radius $r=0.05$.}
%\label{configuration_csm_and_fsi_2D}
%\end{figure}

Control points $A(t)$ (with $A(0) = (0.6,0.2)$) are fixed at the 
trailing edge of the structure, measuring $x$- and $y$-deflections of the beam.

Details 
on parameters and evaluation functionals and other results 
can be found in \cite{HrTu06b,BuSc06,DeHaeAnnBrVie10,Wi11}. 
The Fractional-Step-$\theta$ scheme is used for time discretization with
different time step sizes $k$. However, the time stepping scheme can be 
very easily chosen in the \texttt{main.cc} function by declaring
\begin{lstlisting}
#define TSP1 ForwardEulerProblem
#define TSP2 BackwardEulerProblem
#define TSP3 CrankNicolsonProblem
#define TSP4 ShiftedCrankNicolsonProblem
#define TSP5 FractionalStepThetaProblem
\end{lstlisting}
and then using in the code the designated scheme, 
for example here the Fractional-Step-$\theta$ scheme
\texttt{TSP5}.

The quantities of interest are evaluations of 
$x$- and $y$ displacement at the point $A(0) = (0.6,0.2)$
and the drag and lift forces acting on the cylinder and the elastic beam:
\begin{align}
\label{drag_lift_forces}
(F_D , F_L) 
= {\int_{S_f} \sigma_f \cdot n_f \, ds + 
\int_{\Gamma_i} \sigma_s \cdot n_s \, ds},
\end{align}
where $S_{f}$ denotes the path over the cylinder in the fluid part and
$\Gamma_i$ the interface between the elastic beam and the 
fluid.

Since the problem is fully nonstationary, the 
dynamics are presents in Figure \ref{res:fsi_2_mesh_and_x_velo}. 
By comparison of our findings in Figure \ref{res:results_ux_and_uy_fsi_2}
with the literature, it can be identified that 
the implementation in \dope{} is correct.



% Bilder von FSI 2 
\begin{figure}[h]
\centering
{\includegraphics[width=6cm]{Pictures/visit_fsi_2_CNn_t_2e-2_global_3_biharmonic_mesh8070_scale.png}}
{\includegraphics[width=6cm]{Pictures/visit_fsi_2_CNn_t_2e-2_global_3_biharmonic_x_velo8070_scale.png}}
\caption{FSI 2 test case: mesh (left) and velocity profile in vertical 
direction (right) at time $t=16.14s$.}
\label{res:fsi_2_mesh_and_x_velo}
\end{figure}

\begin{figure}
\centering
{\includegraphics[width=5.8cm]{Pictures/ux_FSI_2_FS_t_3e-2_t_15e-3_global_2_Hron_grid.pdf}}
{\includegraphics[width=5.8cm]{Pictures/uy_FSI_2_FS_t_3e-2_t_15e-3_global_2_Hron_grid.pdf}}
{\includegraphics[width=5.8cm]{Pictures/Drag_fluid_FSI_2_FS_t_3e-2_t_15e-3_global_2_Hron_grid.pdf}}
{\includegraphics[width=5.8cm]{Pictures/Lift_fluid_FSI_2_FS_t_3e-2_t_15e-3_global_2_Hron_grid.pdf}}
\caption{FSI 2: the deflections of the beam, $u_x(A)$ and $u_y(A)$ (in $cm$), and 
the drag $F_D$ and the lift $F_L$ evaluation (in $kg/m\,s^2$) are displayed versus
time (in $s$).
} 
\label{res:results_ux_and_uy_fsi_2}
\end{figure}


\subsection{Compliance minimization}
Winni
Results already obtained.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
\label{conclusions}
In this article, we described the features 
and applications of the \dope{} project, which 
was initiated at the Heidelberg University in 2010.
Specifically, the applications cover a broad 
spectrum of numerical exmamples motivated 
by different disciplines. 
Currently, we are developing concepts for the efficient 
numerical solution of time-dependent optimization
problems governed by PDEs. 

\section{Outlook}
\todo{Was wollen wir noch in den nächsten 1-2 Jahren erreichen?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\bibliographystyle{abbrvnat}
\bibliographystyle{acmsmall}
\bibliography{lit}
%


\end{document}


